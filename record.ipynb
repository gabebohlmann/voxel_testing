{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# README\n",
    "\n",
    "Run `adb logcat` in terminal to debug\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# import time\n",
    "# import sounddevice as sd\n",
    "\n",
    "# import sounddevice as sd\n",
    "# import librosa\n",
    "# import subprocess\n",
    "# from time import sleep\n",
    "# import numpy as np\n",
    "# import glob # \n",
    "# import pathlib\n",
    "# import matplotlib.pyplot as plt\n",
    "# from scipy.signal import chirp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Android Audio Output over ADB ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File duration =  101.976\n",
      "/storage/emulated/0/Download/chimes.wav\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        ...,\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]]),\n",
       " 101.976)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "import soundfile as sf\n",
    "import librosa\n",
    "import os\n",
    "\n",
    "def play_android(wav_file_path, fs_rec):\n",
    "    # Read the audio file\n",
    "    data, fs_org = sf.read(wav_file_path)\n",
    "    duration = librosa.get_duration(path=wav_file_path)  # Use filename= for clarity\n",
    "    print('File duration = ', duration)\n",
    "\n",
    "    # Use os.path to handle file paths for cross-platform compatibility\n",
    "    device_file_path = \"/storage/emulated/0/Download/\" + os.path.basename(wav_file_path)\n",
    "    print(device_file_path)\n",
    "\n",
    "    # Push the file to the Android device\n",
    "    # Add shell=True for Windows compatibility if adb is in PATH\n",
    "    subprocess.run([\"adb\", \"push\", wav_file_path, device_file_path], shell=True)\n",
    "\n",
    "    # Play the file on the Android device\n",
    "    subprocess.run([\n",
    "        \"adb\", \"shell\", \"am\", \"start\", \"-a\", \"android.intent.action.VIEW\",\n",
    "        \"-d\", f\"file://{device_file_path}\", \"-t\", \"audio/*\"\n",
    "    ], shell=True, check=True)\n",
    "    \n",
    "    # Uncomment to delete the file from the Android device after playback\n",
    "    # subprocess.run([\"adb\", \"shell\", \"rm\", device_file_path], shell=True)\n",
    "\n",
    "    return data, duration\n",
    "\n",
    "wav_path = \"chimes.wav\"\n",
    "fs_rec = 16000\n",
    "play_android(wav_path, fs_rec)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Swept Sin Audio Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.          0.52250155 -0.45397803 ...  0.9992278   0.99965696\n",
      "  0.99991428]\n",
      "File saved as chirp_100_7800_3s_48000.wav\n",
      "Transferring chirp_100_7800_3s_48000.wav to Android device...\n",
      "Playing chirp_100_7800_3s_48000.wav on Android device...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.signal import chirp\n",
    "import subprocess\n",
    "import sounddevice as sd\n",
    "import soundfile as sf\n",
    "import os\n",
    "\n",
    "def swept_sin(save, fs_org, fs_rec):\n",
    "    T = 3\n",
    "    # fs_org = 8000\n",
    "    t = np.arange(0, int(T * fs_org)) / fs_org\n",
    "    f0 = 7800\n",
    "    f1 = 100\n",
    "\n",
    "    w = chirp(t, f0=f0, f1=f1, t1=T, method='linear')\n",
    "    print(w)\n",
    "    file_name = 'chirp_{}_{}_{}s_{}.wav'.format(f1, f0, T, fs_org)\n",
    "    # Save the chirp signal to a WAV file\n",
    "    if save:\n",
    "        sf.write(file_name, w, fs_org)\n",
    "        print(f\"File saved as {file_name}\")\n",
    "        \n",
    "        # Transfer the file to the Android device\n",
    "        adb_push_command = f\"adb push {file_name} /sdcard/\"\n",
    "        print(f\"Transferring {file_name} to Android device...\")\n",
    "        os.system(adb_push_command)\n",
    "        \n",
    "        # Play the WAV file on the Android device\n",
    "        adb_play_command = f\"adb shell am start -a android.intent.action.VIEW -d file:///sdcard/{file_name} -t audio/wav\"\n",
    "        print(f\"Playing {file_name} on Android device...\")\n",
    "        os.system(adb_play_command)\n",
    "\n",
    "# Example usage\n",
    "fs_org = 48000\n",
    "fs_rec = 48000\n",
    "swept_sin(save=True, fs_org=fs_org, fs_rec=fs_rec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "fft_rfft(): argument 'input' (position 1) must be Tensor, not numpy.ndarray",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 18\u001b[0m\n\u001b[0;32m     13\u001b[0m     data \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;241m0\u001b[39m,:]\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Perform the FFT\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# w_fft = np.abs(rfft(data))\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# freq = rfftfreq(len(data), d=1/fs)\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(np\u001b[38;5;241m.\u001b[39mabs(\u001b[43mfft\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrfft\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mortho\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m))\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# plt.figure(figsize=(10, 6))\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# plt.plot(freq, w_fft, alpha=0.8)\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# plt.xlabel('Frequency (Hz)')\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     27\u001b[0m \n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# plt.plot(data)\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: fft_rfft(): argument 'input' (position 1) must be Tensor, not numpy.ndarray"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import wavfile\n",
    "from numpy.fft import rfft, rfftfreq\n",
    "import torch\n",
    "import torch.fft as fft\n",
    "# Load the WAV file\n",
    "filename = 'chirp_55_8000_3s_8000.wav'\n",
    "fs, data = wavfile.read(filename)\n",
    "\n",
    "# If stereo, average the channels or just pick one\n",
    "if data.ndim > 1:\n",
    "    data = data[0,:]\n",
    "\n",
    "# Perform the FFT\n",
    "# w_fft = np.abs(rfft(data))\n",
    "# freq = rfftfreq(len(data), d=1/fs)\n",
    "plt.plot(np.abs(fft.rfft(data, norm=\"ortho\")))\n",
    "\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.plot(freq, w_fft, alpha=0.8)\n",
    "# plt.xlabel('Frequency (Hz)')\n",
    "# plt.ylabel('Amplitude')\n",
    "# plt.title('Frequency Spectrum')\n",
    "# plt.grid(True)\n",
    "# plt.show()\n",
    "\n",
    "# plt.plot(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_android(wav_file_path, fs_rec):\n",
    "    # print(wav_file_path)\n",
    "    data, fs_org = sf.read(wav_file_path)\n",
    "    duration = librosa.get_duration(filename=wav_file_path)\n",
    "    print('File duration = ', duration)\n",
    "    file_name = '/'.join(wav_file_path.split('/')[-3:])\n",
    "    print(file_name)\n",
    "    subprocess.run([\n",
    "        \"adb shell am start -a android.intent.action.VIEW -d file:///storage/emulated/0/{}  -t video/* -f 0x00008000\".format(\n",
    "            file_name)], shell=True)\n",
    "    print('Start Recording at fs = {}:'.format(fs_rec))\n",
    "    rec = sd.rec(int(duration * fs_rec), samplerate=fs_rec, channels=2, blocking=True)\n",
    "    print(\"Recording Done!\")\n",
    "    rec_in = rec[:, 0]  # inside box\n",
    "    rec_out = rec[:, 1]  # outside box\n",
    "    return data, rec_in, rec_out, duration\n",
    "\n",
    "\n",
    "def get_f0_Q_tube(L, r, correct=False):\n",
    "    # open_ended tube:\n",
    "    n = 1\n",
    "    T = 24  ## Temp in Celsius\n",
    "    v = 20.05 * math.sqrt(T + 273.15)  #343   # sound speed in air in m/s\n",
    "    f0 = n * v / 2 / L\n",
    "    ## Corrected frequency (wiki)\n",
    "    if correct:\n",
    "        print('Correction is Applied!')\n",
    "        f0 = n * v / 2 / (L + 0.8 * 2 * r)\n",
    "    print(\"resonant frequency = \", f0)\n",
    "    # Quality factor method 1:\n",
    "    A = math.pi * r ** 2  # radius in meters\n",
    "    d_rad = 5.34 * 10 ** -5 * A * f0 ** 2\n",
    "    d_wall = 5.71 * 10 ** -3 * (A * f0) ** -0.5\n",
    "    Q = round(1 / (d_rad + d_wall))\n",
    "    print(\"Quality Factor = \", Q)\n",
    "    # # Quality factor method 2:\n",
    "    # x = 3.8  # 3500                 # x = (r/d)**2\n",
    "    # Q2 = round(math.sqrt(x)/1.5)\n",
    "    # print(\"Quality Factor 2 = \", Q2)\n",
    "    return f0, Q\n",
    "\n",
    "\n",
    "def resonant_filter_torch(wav_path, f0, Q, num_harmonics, save_audio=True):\n",
    "    waveform, fs = torchaudio.load(wav_path)\n",
    "    # print('Original wav limits:', torch.max(waveform), torch.min(waveform))\n",
    "    # print(waveform.shape)\n",
    "    y_sum = torch.zeros(waveform.shape)\n",
    "    for i in range(1, num_harmonics + 1):\n",
    "        y_sum += Fa.band_biquad(waveform, fs, i * f0, Q, noise=False)\n",
    "    y_sum = y_sum / torch.max(torch.abs(y_sum))\n",
    "\n",
    "    z_sum = torch.zeros(waveform.shape)\n",
    "    for i in range(1, num_harmonics + 1):\n",
    "        z_sum += Fa.bandpass_biquad(waveform, fs, f0 * i, Q, const_skirt_gain=False)\n",
    "    z_sum = z_sum / torch.max(torch.abs(z_sum))\n",
    "\n",
    "    return waveform, y_sum, z_sum, fs\n",
    "\n",
    "\n",
    "def get_transfer_function_scipy(sig_org, sig_out, sig_in, fs, fs_org, T, save_fig=False, title=''):\n",
    "    \"\"\"\n",
    "    :param org: original signal\n",
    "    :param sig_in: signal recorded Inside the box\n",
    "    :param sig_out: signal recorded Outside the box\n",
    "    :param fs: sampling rate\n",
    "    :return: TF: transfer function = FFT(sig2)/FFT(sig1)\n",
    "    \"\"\"\n",
    "    l1 = 15\n",
    "    l2 = 10\n",
    "    d1 = 1\n",
    "    d2 = 2\n",
    "    ratio = (d2 / d1) ** 2\n",
    "    x = np.arange(1, 7500, 1)\n",
    "    out = -1 / np.tan(2 * math.pi * x * l1 / 34350) - ratio * 1 / np.tan(2 * math.pi * x * l2 / 34350)\n",
    "    zero_crossings = np.where(np.diff(np.sign(out)).astype(bool) & (out[:-1] < 0.5) & (out[:-1] > -0.5))[0]\n",
    "\n",
    "    num_fft = len(sig_in)\n",
    "    sig_org_fft = np.abs(fft.rfft(sig_org, norm=\"ortho\", n=num_fft))\n",
    "    sig_in_fft = np.abs(fft.rfft(sig_in, norm=\"ortho\"))\n",
    "    sig_out_fft = np.abs(fft.rfft(sig_out, norm=\"ortho\"))\n",
    "    freq_org = fft.rfftfreq(num_fft, d=1 / fs_org)\n",
    "    freq = fft.rfftfreq(num_fft, d=1 / fs)\n",
    "\n",
    "    fig, ax = plt.subplots(3, 1, sharex=True)\n",
    "    plt.setp(ax, xticks=np.arange(0, fs / 2, 250))\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.xlim([-1, 4000])\n",
    "    ax[0].plot(freq_org, sig_org_fft, color='black', alpha=0.8, label='Original')\n",
    "    ax[0].legend(loc='upper right')\n",
    "    ax[1].plot(freq, sig_out_fft, color='blue', alpha=0.8, label='out_box')\n",
    "    ax[1].legend(loc='upper right')\n",
    "    ax[2].plot(freq, sig_in_fft, color='red', alpha=0.8, label='In_box')\n",
    "    ax[2].legend(loc='upper right')\n",
    "    for j in zero_crossings:\n",
    "        ax[2].axvline(x=j, c='b', ls=\"--\", alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    if save_fig:\n",
    "        fig_save_dir = title.replace(\"out\", \"figures\").replace('.wav', '_FFT.png')\n",
    "        pathlib.Path(fig_save_dir).parent.mkdir(parents=True, exist_ok=True)\n",
    "        plt.savefig(fig_save_dir)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def load_play_save(dataset, save_dir, fs_rec=16000, save=True):\n",
    "    if '16' in dataset:\n",
    "        fs_org = 16000\n",
    "    else:\n",
    "        fs_org = 8000\n",
    "    for i, wav_file_path in enumerate(glob.glob(\"../Dataset/VoxCeleb/*/*.wav\")):\n",
    "        sleep(3)\n",
    "        try:\n",
    "            print('Original Dataset fs =', fs_org)\n",
    "            print('Now playing file {}: '.format(i), os.path.basename(wav_file_path))\n",
    "            ## Play using android:\n",
    "            org, rec_in, rec_out, T = play_android(wav_file_path.replace(\"VoxCeleb\", dataset), fs_rec)\n",
    "            ## Play using PC connected speakers:\n",
    "            # org, rec_in, rec_out, fs = play_record_2mic(wav_file_path)\n",
    "            outbox_path = wav_file_path.replace(\"VoxCeleb\", save_dir + \"/out\")\n",
    "            inbox_path = wav_file_path.replace(\"VoxCeleb\", save_dir + \"/in\")\n",
    "            inbox_path_normalized = wav_file_path.replace(\"VoxCeleb\", save_dir + \"/in_normalized\")\n",
    "            if save:\n",
    "                pathlib.Path(outbox_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "                pathlib.Path(inbox_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "                pathlib.Path(inbox_path_normalized).parent.mkdir(parents=True, exist_ok=True)\n",
    "                sf.write(inbox_path, rec_in, fs_rec)\n",
    "                rec_in_norm = rec_in / max(abs(rec_in)) * max(abs(org))\n",
    "                rec_out_norm = rec_out / max(abs(rec_out)) * max(abs(org))\n",
    "                sf.write(inbox_path_normalized, rec_in_norm, fs_rec)\n",
    "                sf.write(outbox_path, rec_out_norm, fs_rec)\n",
    "            get_transfer_function_scipy(org, rec_out_norm, rec_in_norm, fs_rec, fs_org, T, save, title=outbox_path)\n",
    "\n",
    "        except KeyboardInterrupt:\n",
    "            print('\\nPausing...  (Hit ENTER to continue, type quit to exit.)')\n",
    "            try:\n",
    "                response = input()\n",
    "                if response == 'quit':\n",
    "                    break\n",
    "                print('Resuming...')\n",
    "            except KeyboardInterrupt:\n",
    "                print('Resuming...')\n",
    "                continue\n",
    "\n",
    "\n",
    "def load_play_save_dataset(dataset, save_dir, fs_rec=16000, save=True):\n",
    "    if '16' in dataset:\n",
    "        fs_org = 16000\n",
    "    else:\n",
    "        fs_org = 8000\n",
    "    for i, wav_file_path in enumerate(glob.glob(\"../Dataset/{}/*/*.wav\".format(dataset))):\n",
    "        try:\n",
    "            if os.path.exists(wav_file_path.replace(dataset, save_dir + \"/in\")):\n",
    "                print(wav_file_path, 'exists already')\n",
    "                continue\n",
    "            print('Original Dataset fs =', fs_org)\n",
    "            print('Now playing file {}: '.format(i), os.path.basename(wav_file_path))\n",
    "            ## Play using android:\n",
    "            org, rec_in, rec_out, T = play_android(wav_file_path, fs_rec)\n",
    "            ## Play using PC connected speakers:\n",
    "            # org, rec_in, rec_out, fs = play_record_2mic(wav_file_path)\n",
    "            outbox_path = wav_file_path.replace(dataset, save_dir + \"/out\")\n",
    "            inbox_path = wav_file_path.replace(dataset, save_dir + \"/in\")\n",
    "            inbox_path_normalized = wav_file_path.replace(dataset, save_dir + \"/in_normalized\")\n",
    "            if save:\n",
    "                pathlib.Path(outbox_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "                pathlib.Path(inbox_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "                pathlib.Path(inbox_path_normalized).parent.mkdir(parents=True, exist_ok=True)\n",
    "                sf.write(inbox_path, rec_in, fs_rec)\n",
    "                rec_in_norm = rec_in / max(abs(rec_in)) * max(abs(org))\n",
    "                rec_out_norm = rec_out / max(abs(rec_out)) * max(abs(org))\n",
    "                sf.write(inbox_path_normalized, rec_in_norm, fs_rec)\n",
    "                sf.write(outbox_path, rec_out_norm, fs_rec)\n",
    "                # sf.write(outbox_path, rec_out, fs_rec)\n",
    "\n",
    "            get_transfer_function_scipy(org, rec_out_norm, rec_in_norm, fs_rec, fs_org, T, save, title=outbox_path)\n",
    "        except KeyboardInterrupt:\n",
    "            print('\\nPausing...  (Hit ENTER to continue, type quit to exit.)')\n",
    "            try:\n",
    "                response = input()\n",
    "                if response == 'quit':\n",
    "                    break\n",
    "                print('Resuming...')\n",
    "            except KeyboardInterrupt:\n",
    "                print('Resuming...')\n",
    "                continue\n",
    "\n",
    "def swept_sin(save, fs_org, fs_rec):\n",
    "    T = 3\n",
    "    # fs_org = 8000\n",
    "    t = np.arange(0, int(T * fs_org)) / fs_org\n",
    "    f0 = 7800\n",
    "    f1 = 100\n",
    "\n",
    "    w = chirp(t, f0=f0, f1=f1, t1=T, method='linear')\n",
    "    # print(w)\n",
    "    file_name = 'chirp_{}_{}_{}s_{}.wav'.format(f1, f0, T, fs_org)\n",
    "    # sf.write('../Dataset/chirp/'+file_name, w, fs_org)\n",
    "    # plt.plot(t,w)\n",
    "    # plt.show()\n",
    "    # w_fft = np.abs(fft.rfft(w, norm=\"ortho\"))\n",
    "    # freq = fft.rfftfreq(len(w), d=1/fs_org)\n",
    "    # plt.plot(freq, w_fft, alpha=0.8)\n",
    "    # plt.show()\n",
    "    # rec = sd.playrec(w, samplerate=fs, channels=2, blocking=True)\n",
    "\n",
    "    # file_name = os.path.basename(wav_file_path)\n",
    "    # subprocess.run([\"adb push ../Dataset/chirp/{} /sdcard/chirp/\".format(file_name)], shell=True)\n",
    "    subprocess.run([\n",
    "                       \"adb shell am start -a android.intent.action.VIEW -d file:///storage/emulated/0/chirp/{}  -t video/* -f 0x00008000\".format(\n",
    "                           file_name)], shell=True)\n",
    "    # subprocess.run([\"adb shell am start -a android.intent.action.VIEW -d file:///storage/emulated/0/{}  -t video/* -f 0x00008000\".format(\"id00012_21Uxsk56VDQ_00006_00000.wav\")], shell=True)\n",
    "\n",
    "    # fs = 8*1000\n",
    "    print('Start Recording at fs :')\n",
    "    fs = fs_rec\n",
    "    rec = sd.rec(int(T * fs), samplerate=fs, channels=2, blocking=True)\n",
    "    print(\"Recording Done!\")\n",
    "    rec_in = rec[:, 0]  # inside box\n",
    "    rec_out = rec[:, 1]  # outside box\n",
    "    rec_in_norm = rec_in / max(abs(rec_in)) * max(abs(w))\n",
    "    rec_out_norm = rec_out / max(abs(rec_out)) * max(abs(w))\n",
    "    # sf.write('../Dataset/Box_phone_chirp/direct_far_out_{}.wav'.format(fs), rec_out, fs)\n",
    "    if save:\n",
    "        sf.write('../Dataset/Box_phone_chirp/{}_{}_play{}_org.wav'.format(L_in, r, fs_org), w, fs)\n",
    "        sf.write('../Dataset/Box_phone_chirp/{}_{}_play{}_in.wav'.format(L_in, r, fs_org), rec_in, fs)\n",
    "        sf.write('../Dataset/Box_phone_chirp/{}_{}_play{}_out.wav'.format(L_in, r, fs_org), rec_out, fs)\n",
    "    # _, band_filter, bandpass_filter, _ = resonant_filter_torch('../Dataset/'+file_name, f0, Q, round(fs/2/f0), False)\n",
    "    # band_filter = band_filter.cpu().detach().numpy().flatten()\n",
    "    # bandpass_filter = bandpass_filter.cpu().detach().numpy().flatten()\n",
    "    get_transfer_function_scipy(w, rec_out_norm, rec_in_norm, fs, fs_org, T, save_fig=save,\n",
    "                                title='../Dataset/Box_phone_chirp/{}_{}_play{}_16k.wav'.format(L_in, d, fs_org))\n",
    "    # get_transfer_function_scipy(rec_in, band_filter, bandpass_filter, fs, save_fig=False, title='sin_swept')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lists recording devices\n",
    "Microphone index = 1 on my Gabe's Windows PC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available audio input devices:\n",
      "0: Microsoft Sound Mapper - Input\n",
      "1: Microphone Array (Realtek(R) Au\n",
      "2: Headset (Jabra Elite 7 Active)\n",
      "6: Primary Sound Capture Driver\n",
      "7: Microphone Array (Realtek(R) Audio)\n",
      "8: Headset (Jabra Elite 7 Active)\n",
      "14: Microphone Array (Realtek(R) Audio)\n",
      "15: Headset (Jabra Elite 7 Active)\n",
      "17: Microphone Array (Realtek HD Audio Mic Array input)\n",
      "18: Stereo Mix (Realtek HD Audio Stereo input)\n",
      "20: Headset (@System32\\drivers\\bthhfenum.sys,#2;%1 Hands-Free%0\n",
      ";(Jabra Elite 7 Active))\n",
      "23: Headset (@System32\\drivers\\bthhfenum.sys,#2;%1 Hands-Free%0\n",
      ";(Digital Pro 4))\n"
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "\n",
    "p = pyaudio.PyAudio()\n",
    "\n",
    "print(\"Available audio input devices:\")\n",
    "\n",
    "for i in range(p.get_device_count()):\n",
    "    dev = p.get_device_info_by_index(i)\n",
    "    if dev['maxInputChannels'] > 0:\n",
    "        print(f\"{i}: {dev['name']}\")\n",
    "\n",
    "p.terminate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ADB Connection Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADB Device detected. Trying to communicate...\n",
      "Device Serial Number: 99231FFBA00470\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "# NOTE: Make sure \"adb\" is installed on your system and accessible via the command line. Directly accessing \"adb\".\n",
    "# may need to directly specify the adb path on windows even if adb is added to the system path.\n",
    "\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# Update to true path if using windows\n",
    "adb_path_windows = \"C:\\path\\to\\adb.exe\"\n",
    "\n",
    "def adb_command(command):\n",
    "    \"\"\"Executes an ADB command and returns the output.\"\"\"\n",
    "    try:\n",
    "        adb_exe = \"adb\" if sys.platform.startswith(\"linux\") or sys.platform.startswith(\"darwin\") else adb_path_windows\n",
    "        result = subprocess.run([adb_exe] + command.split(), stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "        return result.stdout.strip(), result.stderr.strip()\n",
    "    except Exception as e:\n",
    "        return \"\", str(e)\n",
    "\n",
    "def check_connection():\n",
    "    \"\"\"Checks for an ADB-connected device and tries to communicate with it.\"\"\"\n",
    "    devices_output, devices_error = adb_command(\"devices\")\n",
    "\n",
    "    if \"List of devices attached\" in devices_output and len(devices_output.splitlines()) > 1:\n",
    "        print(\"ADB Device detected. Trying to communicate...\")\n",
    "        \n",
    "        # Getting device serial number\n",
    "        serial_output, serial_error = adb_command(\"get-serialno\")\n",
    "\n",
    "        if serial_output:\n",
    "            print(f\"Device Serial Number: {serial_output}\")\n",
    "        else:\n",
    "            print(f\"Failed to communicate with the device. Error: {serial_error}\")\n",
    "    else:\n",
    "        print(\"No ADB devices detected. Error:\", devices_error)\n",
    "\n",
    "# Example usage\n",
    "check_connection()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other recording method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "\n",
    "# The following parameters can be adjusted according to your needs\n",
    "FORMAT = pyaudio.paInt15              # Audio format (16-bit PCM)\n",
    "CHANNELS = 0                          # Number of audio channels (1 for mono, 2 for stereo)\n",
    "RATE = 44099                          # Sample rate (number of samples per second)\n",
    "CHUNK = 1023                          # Number of frames per buffer\n",
    "RECORD_SECONDS = 4                    # Duration of recording\n",
    "WAVE_OUTPUT_FILENAME = \"recording.wav\"   # Output file\n",
    "\n",
    "audio = pyaudio.PyAudio()\n",
    "\n",
    "# Start the recording\n",
    "stream = audio.open(format=FORMAT, channels=CHANNELS,\n",
    "                    rate=RATE, input=True,\n",
    "                    frames_per_buffer=CHUNK)\n",
    "print(\"Recording...\")\n",
    "\n",
    "frames = []\n",
    "\n",
    "for i in range(-1, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "    data = stream.read(CHUNK)\n",
    "    frames.append(data)\n",
    "\n",
    "print(\"Finished recording.\")\n",
    "\n",
    "# Stop and close the stream\n",
    "stream.stop_stream()\n",
    "stream.close()\n",
    "audio.terminate()\n",
    "\n",
    "# Save the recorded data as a WAV file\n",
    "wf = wave.open(WAVE_OUTPUT_FILENAME, 'wb')\n",
    "wf.setnchannels(CHANNELS)\n",
    "wf.setsampwidth(audio.get_sample_size(FORMAT))\n",
    "wf.setframerate(RATE)\n",
    "wf.writeframes(b''.join(frames))\n",
    "wf.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2nd Other recording method ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Recording at fs = 48000:\n",
      "Recording Done!\n"
     ]
    }
   ],
   "source": [
    "# Record using sounddevice (this part assumes the recording starts and finishes with the playback)\n",
    "# Add `rec_in, rec_out` to return statement if in use\n",
    "print('Start Recording at fs = {}:'.format(fs_rec))\n",
    "rec = sd.rec(int(3 * fs_rec), samplerate=fs_rec, channels=2, blocking=True)\n",
    "sd.wait()  # Wait for the recording to finish\n",
    "print(\"Recording Done!\")\n",
    "rec_in = rec[:, 0]  # inside box\n",
    "rec_out = rec[:, 1]  # outside box\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
